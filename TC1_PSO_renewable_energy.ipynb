{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.special import expit  # Sigmoid function\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return expit(x)\n",
    "    # return np.maximum(0, x)\n",
    "\n",
    "# Define the linear activation function\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "# Define the neural network architecture\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "        \"\"\"\n",
    "        Initialize the neural network\n",
    "        :param input_size: number of input neurons\n",
    "        :param hidden_size: number of hidden neurons\n",
    "        :param output_size: number of output neurons\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # # Initialize weights and biases using Xavier initialization\n",
    "        # self.v = np.random.randn(hidden_size, input_size) * np.sqrt(2.0 / (input_size + hidden_size))\n",
    "        # self.v0 = np.zeros(hidden_size)\n",
    "        # self.w = np.random.randn(output_size, hidden_size) * np.sqrt(2.0 / (hidden_size + output_size))\n",
    "        # self.w0 = np.zeros(output_size)\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.v = np.random.rand(hidden_size, input_size)\n",
    "        self.v0 = np.random.rand(hidden_size)\n",
    "        self.w = np.random.rand(output_size, hidden_size)\n",
    "        self.w0 = np.random.rand(output_size)\n",
    "\n",
    "    def predict(self, phi: np.ndarray) -> np.ndarray:   \n",
    "        \"\"\"\n",
    "        Make a prediction with the neural network\n",
    "        :param phi: input data\n",
    "        :return: prediction\n",
    "        \"\"\"\n",
    "        hidden_input = np.dot(self.v, phi) + self.v0\n",
    "        hidden_output = sigmoid(hidden_input)\n",
    "        output = np.dot(self.w, hidden_output) + self.w0\n",
    "        return linear(output)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return np.concatenate([self.v.flatten(), self.v0, self.w.flatten(), self.w0])\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        v_end = self.hidden_size * self.input_size\n",
    "        v0_end = v_end + self.hidden_size\n",
    "        w_end = v0_end + (self.output_size * self.hidden_size)\n",
    "\n",
    "        self.v = weights[:v_end].reshape(self.hidden_size, self.input_size)\n",
    "        self.v0 = weights[v_end:v0_end]\n",
    "        self.w = weights[v0_end:w_end].reshape(self.output_size, self.hidden_size)\n",
    "        self.w0 = weights[w_end:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the fitness function\n",
    "def fitness(network, data, targets):\n",
    "    predictions = np.array([network.predict(phi) for phi in data])\n",
    "    rmse = mean_squared_error(targets, predictions, squared=False)\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSO:\n",
    "    def __init__(self, network, data, targets, num_particles, max_iter, w=0.5, c1=2.0, c2=2.0):\n",
    "        self.network = network\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.num_particles = num_particles\n",
    "        self.max_iter = max_iter\n",
    "        self.w = w\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "\n",
    "        self.dim = len(network.get_weights())\n",
    "        self.swarm = np.random.rand(num_particles, self.dim)\n",
    "        self.velocity = np.zeros((num_particles, self.dim))\n",
    "        self.pbest = self.swarm.copy()\n",
    "        self.lbest = self.swarm.copy()\n",
    "        self.pbest_fitness = np.array([self.evaluate_fitness(weights) for weights in self.swarm])\n",
    "        self.lbest_fitness = self.pbest_fitness.copy()\n",
    "\n",
    "    def evaluate_fitness(self, weights):\n",
    "        self.network.set_weights(weights)\n",
    "        return fitness(self.network, self.data, self.targets)\n",
    "\n",
    "    def calculate_diversity(self):\n",
    "        return np.mean(np.linalg.norm(self.swarm - np.mean(self.swarm, axis=0), axis=1))\n",
    "\n",
    "    def adaptive_neighborhood(self, diversity):\n",
    "        neighborhood_size = min(max(2, int(self.num_particles * (1 - diversity))), self.num_particles)\n",
    "        for i in range(self.num_particles):\n",
    "            distances = np.linalg.norm(self.swarm - self.swarm[i], axis=1)\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            neighborhood_indices = sorted_indices[:neighborhood_size]\n",
    "            best_neighbor_index = np.argmin(self.pbest_fitness[neighborhood_indices])\n",
    "            self.lbest[i] = self.pbest[neighborhood_indices[best_neighbor_index]]\n",
    "            self.lbest_fitness[i] = self.pbest_fitness[neighborhood_indices[best_neighbor_index]]\n",
    "\n",
    "    def optimize(self):\n",
    "        for t in range(self.max_iter):\n",
    "            for i in range(self.num_particles):\n",
    "                self.network.set_weights(self.swarm[i])\n",
    "                current_fitness = fitness(self.network, self.data, self.targets)\n",
    "                \n",
    "                # Update personal best\n",
    "                if current_fitness < self.pbest_fitness[i]:\n",
    "                    self.pbest[i] = self.swarm[i].copy()\n",
    "                    self.pbest_fitness[i] = current_fitness\n",
    "\n",
    "            # Calculate swarm diversity\n",
    "            diversity = self.calculate_diversity()\n",
    "\n",
    "            # Adaptive neighborhood adjustment\n",
    "            self.adaptive_neighborhood(diversity)\n",
    "\n",
    "            for i in range(self.num_particles):\n",
    "                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n",
    "                self.velocity[i] = (self.w * self.velocity[i] +\n",
    "                                    self.c1 * r1 * (self.pbest[i] - self.swarm[i]) +\n",
    "                                    self.c2 * r2 * (self.lbest[i] - self.swarm[i]))\n",
    "                self.swarm[i] += self.velocity[i]\n",
    "\n",
    "            # Update the best weights found\n",
    "            best_particle = np.argmin(self.pbest_fitness)\n",
    "            best_weights = self.pbest[best_particle]\n",
    "            self.network.set_weights(best_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file found locally.\n",
      "Loading CSV file...\n",
      "Dataset loaded\n",
      "Preprocessing data...\n",
      "Percent of data in training set: 80.01%\n",
      "Percent of data in test set: 19.99%\n",
      "Standardizing features...\n",
      "Standardization complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "csv_filename = 'Renewable_Energy_Consumption_in_the_US.csv'\n",
    "csv_url = \"https://storage.googleapis.com/kagglesdsdata/datasets/4962496/8352264/dataset.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240531%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240531T131003Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=67056505172956b7c17a6afbde9d66ab941769f53d09951ab578d832886b88c9e9d8cc2eda441b3eb97f0ef863c474c6b742b040e39d242f9410580de0e007f12598eb6fda4ca1d3b01347657507877a0e62d658b42ee2b13147f9fe643d445120d56cc1f8741d9d9e750add7d06a351b811c602f282b7ae632c4cf372138addbad3bb50a6b6a6f9d0596bfd41779c4b901c8265669d00c23e494f669dee5f0c81ebd9ba80360147b480ebe164b3de9679b1ff62490833de99112e01354c3286b3f0118d89625e75092c6711ff6119571a3d0c3f683d3c1cf13a4a648242e435f7a26756e2e0ece1dc62dd47adee56b370a6c78f21dca7b1ab7418e2a4e6cf0d\"\n",
    "\n",
    "# Download the dataset if not available locally\n",
    "if not os.path.exists(csv_filename):\n",
    "    print(\"Downloading the dataset...\")\n",
    "    response = requests.get(csv_url)\n",
    "    with open(csv_filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"CSV file found locally.\")\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading CSV file...\")\n",
    "data = pd.read_csv(csv_filename)\n",
    "print(\"Dataset loaded\")\n",
    "\n",
    "# Preprocess the data\n",
    "print(\"Preprocessing data...\")\n",
    "data = data.dropna(subset=['Total Renewable Energy'])\n",
    "\n",
    "# Convert date to datetime\n",
    "data['dt'] = pd.to_datetime(data[['Year', 'Month']].assign(DAY=1))\n",
    "\n",
    "def create_lag_features(data, lags=1, targets=['Total Renewable Energy']):\n",
    "    df = pd.DataFrame(data)\n",
    "    columns = [df[targets].shift(i) for i in range(lags, 0, -1)]\n",
    "    columns = [df] + columns\n",
    "    df = pd.concat(columns, axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    # df.columns = ['dt', target] + [f'{target}_lag_{i}' for i in range(1, lags + 1)]\n",
    "    df.columns = ['dt'] + targets + [f'{target}_lag_{i}' for target in targets for i in range(1, lags + 1)]\n",
    "    return df\n",
    "\n",
    "# Creating time series\n",
    "# Using LandAverageTemperatureUncertainty as exogenous variable\n",
    "ts = data[['dt', 'Total Renewable Energy']].dropna().copy()\n",
    "\n",
    "# Create lag features\n",
    "lags = 3  # Number of lag observations\n",
    "data_lagged = create_lag_features(ts, lags)\n",
    "\n",
    "# Select features and target variable\n",
    "X = data_lagged.drop(['dt', 'Total Renewable Energy'], axis=1)\n",
    "y = data_lagged['Total Renewable Energy']\n",
    "\n",
    "# Split the data using TimeSeriesSplit\n",
    "time_split = TimeSeriesSplit(n_splits=4)\n",
    "train_index, test_index = list(time_split.split(X))[-1]\n",
    "X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "print(f\"Percent of data in training set: {len(X_train) / len(X) * 100:.2f}%\")\n",
    "print(f\"Percent of data in test set: {len(X_test) / len(X) * 100:.2f}%\")\n",
    "\n",
    "# Standardize the features\n",
    "print(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(\"Standardization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network structure\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 50\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network\n",
    "network = NeuralNetwork(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network using PSO\n",
    "pso = PSO(network, X_train, y_train, num_particles=30, max_iter=100)\n",
    "pso.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_plot_train['dt'] = data_lagged[data_lagged.index < X_plot_train.shape[0]]['dt']\n",
    "X_plot_train['Total Renewable Energy'] = y_train\n",
    "\n",
    "X_plot_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "X_plot_test['dt'] = data_lagged[data_lagged.index >= X_plot_train.shape[0]]['dt'].reset_index(drop=True)\n",
    "X_plot_test['Total Renewable Energy'] = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'go' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m X_plot_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_lagged[data_lagged\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m X_plot_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m X_plot_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Renewable Energy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mgo\u001b[49m\u001b[38;5;241m.\u001b[39mFigure()\n\u001b[1;32m     10\u001b[0m fig\u001b[38;5;241m.\u001b[39madd_trace(go\u001b[38;5;241m.\u001b[39mScatter(x\u001b[38;5;241m=\u001b[39mX_plot_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m], y\u001b[38;5;241m=\u001b[39mX_plot_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Renewable Energy\u001b[39m\u001b[38;5;124m'\u001b[39m], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     11\u001b[0m fig\u001b[38;5;241m.\u001b[39madd_trace(go\u001b[38;5;241m.\u001b[39mScatter(x\u001b[38;5;241m=\u001b[39mX_plot_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m], y\u001b[38;5;241m=\u001b[39mX_plot_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Renewable Energy\u001b[39m\u001b[38;5;124m'\u001b[39m], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m, opacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'go' is not defined"
     ]
    }
   ],
   "source": [
    "X_plot_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_plot_train['dt'] = data_lagged[data_lagged.index < X_plot_train.shape[0]]['dt']\n",
    "X_plot_train['Total Renewable Energy'] = y_train\n",
    "\n",
    "X_plot_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "X_plot_test['dt'] = data_lagged[data_lagged.index >= X_plot_train.shape[0]]['dt'].reset_index(drop=True)\n",
    "X_plot_test['Total Renewable Energy'] = y_test.reset_index(drop=True)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=X_plot_train['dt'], y=X_plot_train['Total Renewable Energy'], mode='lines', name='Train'))\n",
    "fig.add_trace(go.Scatter(x=X_plot_test['dt'], y=X_plot_test['Total Renewable Energy'], mode='lines', name='Test', opacity=0.8))\n",
    "fig.add_trace(go.Scatter(x=X_plot_test['dt'], y=y_pred, mode='lines', name='Predicted'))\n",
    "fig.show('svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
